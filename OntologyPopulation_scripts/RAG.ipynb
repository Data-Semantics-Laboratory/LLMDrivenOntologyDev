{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcep-n9ipCkF"
      },
      "outputs": [],
      "source": [
        "!pip -q install langchain\n",
        "!pip -q install bitsandbytes accelerate xformers einops\n",
        "!pip -q install datasets loralib sentencepiece\n",
        "!pip -q install pypdf\n",
        "\n",
        "!pip -q install sentence_transformers\n",
        "!pip install chromadb\n",
        "\n",
        "!pip install openai\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders import Docx2txtLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from huggingface_hub import notebook_login\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "from langchain import HuggingFacePipeline\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "E41J4L5ApFge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/docs1'\n",
        "\n"
      ],
      "metadata": {
        "id": "DJuTKdzUpTCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(directory_path)"
      ],
      "metadata": {
        "id": "Qms_Lz9mpWov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=[]\n",
        "for file in files:\n",
        "\n",
        "  if file.endswith(\".pdf\"):\n",
        "    pdf_path=\"\"+file\n",
        "    loader=PyPDFLoader(pdf_path)\n",
        "    document.extend(loader.load())\n",
        "  elif file.endswith('.docx') or file.endswith('.doc'):\n",
        "    doc_path=\"\"+file\n",
        "    loader=Docx2txtLoader(doc_path)\n",
        "    document.extend(loader.load())\n",
        "  elif file.endswith('.txt'):\n",
        "    text_path = \"/content/drive/MyDrive/docs1/\"+file\n",
        "\n",
        "    loader=TextLoader(text_path, encoding = 'UTF-8')\n",
        "    document.extend(loader.load())"
      ],
      "metadata": {
        "id": "slzsQio_pafL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# document_splitter=CharacterTextSplitter(separator='\\n', chunk_size=500, chunk_overlap=100)\n",
        "document_splitter= RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"])"
      ],
      "metadata": {
        "id": "jnqp9N3JpgGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_chunks=document_splitter.split_documents(document)"
      ],
      "metadata": {
        "id": "V9he9MAxpktA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(document_chunks)"
      ],
      "metadata": {
        "id": "k6ISjWRipm9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "e5Z3IqsQpp7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"]=\"s\"\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "V95vPrDMptUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb=Chroma.from_documents(document_chunks,embedding=embeddings, persist_directory='./data')"
      ],
      "metadata": {
        "id": "BrbYIszzp3Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "1YyZo24ap5mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llama"
      ],
      "metadata": {
        "id": "VWsjrI6IqH5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "5lxKz8o_p8HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##llama\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                          use_auth_token=True,)\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "                                             device_map='auto',\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             use_auth_token=True,\n",
        "                                              #load_in_8bit=True,\n",
        "                                              load_in_4bit=True\n",
        "                                             )"
      ],
      "metadata": {
        "id": "wJW-HdI3p-0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe=pipeline(\"text-generation\",\n",
        "              model=model,\n",
        "              tokenizer=tokenizer,\n",
        "              torch_dtype=torch.bfloat16,\n",
        "              device_map='auto',\n",
        "              max_new_tokens=512,\n",
        "              min_new_tokens=-1,\n",
        "              top_k=30\n",
        "\n",
        "              )"
      ],
      "metadata": {
        "id": "irMYGDz_qLP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "imjp2AukqOJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT"
      ],
      "metadata": {
        "id": "KgxlSy5lqTSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatOpenAI(temperature=0.7, model_name='gpt-4')"
      ],
      "metadata": {
        "id": "69JFLx4tqVZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngh4mrcXqYC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
      ],
      "metadata": {
        "id": "hGT_dhcfqbNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_qa=ConversationalRetrievalChain.from_llm(llm=llm,\n",
        "                                             retriever=vectordb.as_retriever(search_kwargs={'k':20}),\n",
        "                                             verbose=False, memory=memory)"
      ],
      "metadata": {
        "id": "nJ7wBNRSqb5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=pdf_qa({\"question\":\"Given the following ontology, extract the related parts of the documents match with the ontology, ontology:has_Name(Agent, Name), has_Surname(Agent, Surname), has_First_Name(Agent, First_Name), has_Alternate_Name(Agent, Alternate_Name), recorded_At(Agent_name, Event), recorded_At(Agent_First_Name, Event), recorded_At(Agent_Surname, Event), recorded_At(Agent_Alternate_Name, Event). geerate texts to populate  based on the relations and document\"})"
      ],
      "metadata": {
        "id": "EMmVPtXiqfR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "tuanZLJkqhkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"content/drive/MyDrive/outputn.txt\"\n",
        "\n",
        "# Open the file in write mode\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    # Write the variable's value to the file\n",
        "    file.write(result['answer'])\n"
      ],
      "metadata": {
        "id": "3awpOaMcqj6c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}