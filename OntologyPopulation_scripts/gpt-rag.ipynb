{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814bcd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from huggingface_hub import notebook_login\n",
    "# import torch\n",
    "# import transformers\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from transformers import pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1806991-b424-48b9-8eb6-9007bba6183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e891604",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./wikitextForSlavesOnWikiandEnslaved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030fce0f-3414-435f-9783-176b8807cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a56e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "\n",
    "llm=ChatOpenAI(temperature=0, model_name='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c3e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodule_file_path = \"./ModulesR/WB_Schema_Relationships.txt\"\n",
    "with open(allmodule_file_path, \"r\", encoding=\"utf-8\") as module_file:\n",
    "        module_content = module_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ca6e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33ad6455aed460c85dea3150697477d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sanazsn\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efce6fc31a84156bc63e8f7ecfe1840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ddf5470ec04f48ba5d1ea6afadf215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fb3cc00b574c929149b0f4092321bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28dfe26eea54a84a56beb87e96bc18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d33afb11b14b6db1d1396128649cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611582e5cbea424385cd2d552771f843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838f6514ebd14c6fa8d134d78b32474d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8078407fd5747b3986c67cf434437b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b98fa177b74f8d9fdc244596a5928d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741b2bdb16e4dc1a632e4cd4b809b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af51d38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\sanazsn\\Anaconda3\\envs\\rag\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file = files[1]\n",
    "if file.endswith('.txt'):\n",
    "    document=[]\n",
    "    dir_path = os.path.join(directory_path, file)\n",
    "    text_path = dir_path\n",
    "    loader=TextLoader(text_path, encoding = 'UTF-8')\n",
    "    document.extend(loader.load())\n",
    "    document_splitter= RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"])\n",
    "    document_chunks=document_splitter.split_documents(document)\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vectordb=Chroma.from_documents(document_chunks,embedding=embeddings, persist_directory='./data')\n",
    "    vectordb.persist()\n",
    "    # llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})\n",
    "    memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True,output_key='answer')\n",
    "    pdf_qa=ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                              retriever=vectordb.as_retriever(search_kwargs={'k':10}),\n",
    "                                              verbose=False, memory=memory,return_source_documents=True)\n",
    "    # for j in module_content1:\n",
    "    result=pdf_qa({\"question\":\"Retrieve the related parts of the document that match with this ontology module, modules:\"+str(module_content)+ \"and populate the ontology based on the text in the form of the example format:Example format: Name Record Module:1. has_Name(Agent, Name): has_Name(Joseph Vance Lewis, 'Joseph Vance Lewis') 2. has_Surname(Agent, Surname): has_Surname(Joseph Vance Lewis, 'Lewis') 3. has_First_Name(Agent, First_Name): has_First_Name(Joseph Vance Lewis, 'Joseph').Interagent Relationship Record Module: 1. has_Interagent_Relationship_Type_To(Agent, Relationship_Type): has_Interagent_Relationship_Type_To(Joseph Vance Lewis, 'Enslaver') 2. is_Relationship_To(Agent, Agent): is_Relationship_To(Joseph Vance Lewis, 'Bwril Nate'). Note: The Interagent Relationship Record Module describes the relationship to another agent who is an enslaver or owner. So use the keywords Enslaver or Owner to describe the relationship type. Sex Record Module: 1. has_Sex(Agent, Sex_Type): has_Sex(Joseph Vance Lewis, 'Male'). Occupation Record Module: 1. has_Occupation(Agent, Occupation): has_Occupation(Joseph Vance Lewis, 'Slave, Educator, Lawyer, and Autobiographer'). Age Record Module: 1. has_Age(Agent, Age): has_Age(Joseph Vance Lewis, 72) 2. has_BirthDate(Agent, Date_of_Birth): has_BirthDate(Joseph Vance Lewis, 'December 25, 1853') 3. has_DeathDate(Agent, Date_of_Death): has_DeathDate(Joseph Vance Lewis, 'April 24, 1925'). Person Status Record Module: 1. has_Person_Status (Agent, Person_Status): has_Person_Status(Joseph Vance Lewis, 'Enslaved Person, Lawyer') 2. has_Status_Generating_Event(Person_Status, Event): has_Status_Generating_Event(Enslaved Person, 'Sale of estate of Joseph Dubreuil'), has_Status_Generating_Event(Lawyer, 'Emancipation') 3. recorded_At(Person_Status_information, Event): recorded_At(Enslaved Person, 'Sale of estate of Joseph Dubreuil'), recorded_At(Lawyer, 'Emancipation'). Race Record Module: has_Race_or_Color(Agent, Race_or_Color): has_Race_or_Color(Joseph Vance Lewis, African-American).  Note: Skip the relations for which there is no information listed in the text file.\"})\n",
    "    summ = result['answer']\n",
    "\n",
    "    source_documents = result.get(\"source_documents\", [])\n",
    "    sen=\"\"\n",
    "    for doc in source_documents:\n",
    "        sen = sen + str(doc.page_content)\n",
    "        sen = sen + \"\\n\"\n",
    "    f_name = os.path.join(\"./wikitextForSlavesOnWikiandEnslaved/responses/GPT4_WB_AllModules\",os.path.splitext(file)[0])\n",
    "    if not os.path.exists(f_name):\n",
    "          os.makedirs(f_name, exist_ok=True)\n",
    "    # response_file_path = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_\"f\"{j}_retrieved.txt\")\n",
    "    # response_file_path1 = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_\"f\"{j}_triples.txt\")\n",
    "    response_file_path = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_retrieved.txt\")\n",
    "    response_file_path1 = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_triples.txt\")\n",
    "    with open(response_file_path1, \"w\", encoding=\"utf-8\") as response_file1:\n",
    "        response_file1.write(summ)\n",
    "    with open(response_file_path, \"w\", encoding=\"utf-8\") as response_file:\n",
    "        response_file.write(sen)\n",
    "    # torch.cuda.empty_cache()\n",
    "    \n",
    "    del result\n",
    "    del summ\n",
    "    del source_documents\n",
    "    del sen\n",
    "    memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3cd813-335b-49b3-b802-d431d7a17486",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_path = \"./ModulesR/\"\n",
    "\n",
    "modules_files = os.listdir(m_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7590e69-4fe3-4d06-9cd8-7937fe124871",
   "metadata": {},
   "outputs": [],
   "source": [
    "module_content1={}\n",
    "for f in modules_files:\n",
    "  if f.endswith(\".txt\"):\n",
    "    m_path1 = m_path+f\n",
    "\n",
    "    with open(m_path1, \"r\", encoding=\"utf-8\") as module_file:\n",
    "       file_name = f.replace(\".txt\", \"\")\n",
    "       module_content1[file_name] = module_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = files[1]\n",
    "if file.endswith('.txt'):\n",
    "    document=[]\n",
    "    dir_path = os.path.join(directory_path, file)\n",
    "    text_path = dir_path\n",
    "    loader=TextLoader(text_path, encoding = 'UTF-8')\n",
    "    document.extend(loader.load())\n",
    "    document_splitter= RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, separators=[\" \", \",\", \"\\n\"])\n",
    "    document_chunks=document_splitter.split_documents(document)\n",
    "    # embeddings = OpenAIEmbeddings()\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "    vectordb=Chroma.from_documents(document_chunks,embedding=embeddings, persist_directory='./data')\n",
    "    vectordb.persist()\n",
    "    # llm=HuggingFacePipeline(pipeline=pipe, model_kwargs={'temperature':0})\n",
    "    memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True,output_key='answer')\n",
    "    pdf_qa=ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                              retriever=vectordb.as_retriever(search_kwargs={'k':1}),\n",
    "                                              verbose=False, memory=memory,return_source_documents=True)\n",
    "    for j in module_content1:\n",
    "        result=pdf_qa({\"question\":\"Retrieve the related parts of the document that match with this ontology module, modules:\"+str(module_content1[j])+ \"and populate the ontology based on the text in the form of the example format:Example format: Name Record Module:1. has_Name(Agent, Name): has_Name(Joseph Vance Lewis, 'Joseph Vance Lewis') 2. has_Surname(Agent, Surname): has_Surname(Joseph Vance Lewis, 'Lewis') 3. has_First_Name(Agent, First_Name): has_First_Name(Joseph Vance Lewis, 'Joseph').Interagent Relationship Record Module: 1. has_Interagent_Relationship_Type_To(Agent, Relationship_Type): has_Interagent_Relationship_Type_To(Joseph Vance Lewis, 'Enslaver') 2. is_Relationship_To(Agent, Agent): is_Relationship_To(Joseph Vance Lewis, 'Bwril Nate'). Note: The Interagent Relationship Record Module describes the relationship to another agent who is an enslaver or owner. So use the keywords Enslaver or Owner to describe the relationship type. Sex Record Module: 1. has_Sex(Agent, Sex_Type): has_Sex(Joseph Vance Lewis, 'Male'). Occupation Record Module: 1. has_Occupation(Agent, Occupation): has_Occupation(Joseph Vance Lewis, 'Slave, Educator, Lawyer, and Autobiographer'). Age Record Module: 1. has_Age(Agent, Age): has_Age(Joseph Vance Lewis, 72) 2. has_BirthDate(Agent, Date_of_Birth): has_BirthDate(Joseph Vance Lewis, 'December 25, 1853') 3. has_DeathDate(Agent, Date_of_Death): has_DeathDate(Joseph Vance Lewis, 'April 24, 1925'). Person Status Record Module: 1. has_Person_Status (Agent, Person_Status): has_Person_Status(Joseph Vance Lewis, 'Enslaved Person, Lawyer') 2. has_Status_Generating_Event(Person_Status, Event): has_Status_Generating_Event(Enslaved Person, 'Sale of estate of Joseph Dubreuil'), has_Status_Generating_Event(Lawyer, 'Emancipation') 3. recorded_At(Person_Status_information, Event): recorded_At(Enslaved Person, 'Sale of estate of Joseph Dubreuil'), recorded_At(Lawyer, 'Emancipation'). Race Record Module: has_Race_or_Color(Agent, Race_or_Color): has_Race_or_Color(Joseph Vance Lewis, African-American).  Note: Skip the relations for which there is no information listed in the text file.\"})\n",
    "        summ1 = result['answer']\n",
    "    \n",
    "        source_documents = result.get(\"source_documents\", [])\n",
    "        sen=\"\"\n",
    "        for doc in source_documents:\n",
    "            sen = sen + str(doc.page_content)\n",
    "            sen = sen + \"\\n\"\n",
    "        f_name = os.path.join(\"./wikitextForSlavesOnWikiandEnslaved/responses/GPT4_WB_ModulesByModules\",os.path.splitext(file)[0])\n",
    "        if not os.path.exists(f_name):\n",
    "              os.makedirs(f_name, exist_ok=True)\n",
    "        response_file_path = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_\"f\"{j}_retrieved.txt\")\n",
    "        response_file_path1 = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_\"f\"{j}_triples.txt\")\n",
    "        # response_file_path = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_retrieved.txt\")\n",
    "        # response_file_path1 = os.path.join(f_name, f\"{os.path.splitext(file)[0]}_triples.txt\")\n",
    "        with open(response_file_path1, \"w\", encoding=\"utf-8\") as response_file1:\n",
    "            response_file1.write(summ1)\n",
    "        with open(response_file_path, \"w\", encoding=\"utf-8\") as response_file:\n",
    "            response_file.write(sen)\n",
    "        # torch.cuda.empty_cache()\n",
    "        \n",
    "        del result\n",
    "        del summ1\n",
    "        del source_documents\n",
    "        del sen\n",
    "        memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a3986-02b5-4804-a00e-a911c7139495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
