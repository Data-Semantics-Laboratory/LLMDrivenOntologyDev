{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making TSVs from ~200 individuals that are both in Enslaved and Wikidata.\n",
    "\n",
    "### Each TSV should contain the triples from Wikidata as:\n",
    "Subject ->  Predicate   -> Object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Dictionary to store found QIDs to avoid redundant API calls\n",
    "foundQIDs = {}\n",
    "QIDCount = {}\n",
    "\n",
    "# Dictionary to store found Props to avoid redundant API calls\n",
    "foundProps = {}\n",
    "PropsCount = {}\n",
    "\n",
    "# Stores any errors to then print out at the end\n",
    "errors = []\n",
    "\n",
    "#Base Query URL for  Wikidata\n",
    "baseURL = \"https://wikidata.org/w/rest.php/wikibase/v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries WikidataProps.json to find the property label\n",
    "def findQID(str):\n",
    "    if str in foundQIDs:\n",
    "        #print(f\"Found {str}: {foundQIDs[str]}\")\n",
    "        QIDCount.update({str: QIDCount.get(str, 0) + 1})\n",
    "        return foundQIDs[str]\n",
    "    else:\n",
    "        endURL = f\"/entities/items/{str}/labels/en\"\n",
    "        response = requests.get(baseURL + endURL)\n",
    "        if response.status_code != 200:\n",
    "            errors.append(f\"Error: {response.status_code} for {str}\")\n",
    "            return None\n",
    "        else:\n",
    "            label = response.text.replace(\"\\\"\", \"\")\n",
    "            foundQIDs.update({str: label})\n",
    "            QIDCount.update({str: 0})\n",
    "            return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queries WikidataProps.json to find the property label\n",
    "def findProperty(str):\n",
    "    if str in foundProps:\n",
    "#       #print(f\"Found Property {str} in foundProps: {foundProps[str]}\")\n",
    "        PropsCount.update({str: PropsCount.get(str, 0) + 1})\n",
    "        return foundProps[str]\n",
    "    else:\n",
    "        endURL = f\"/entities/properties/{str}/labels/en\"\n",
    "        response = requests.get(baseURL + endURL)\n",
    "        if response.status_code != 200:\n",
    "            errors.append(f\"findProperty Error: {response.status_code} for {str}\")\n",
    "            return None\n",
    "        else:\n",
    "            label = response.text.replace(\"\\\"\", \"\")\n",
    "            foundProps.update({str: label})\n",
    "            PropsCount.update({str: 0})\n",
    " #          #print(foundProps[str])\n",
    "            return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 43/133 [03:59<08:20,  5.56s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Check if the line ends with a '.'\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Process the chunk\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     processChunk(chunk)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Reset the chunk\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 93\u001b[0m, in \u001b[0;36mprocessChunk\u001b[0;34m(chunk)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     92\u001b[0m     statementNodes\u001b[38;5;241m.\u001b[39mappend(chunk)\n\u001b[0;32m---> 93\u001b[0m     processS(chunk)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref:\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     95\u001b[0m     referenceNodes\u001b[38;5;241m.\u001b[39mappend(chunk)\n",
      "Cell \u001b[0;32mIn[17], line 33\u001b[0m, in \u001b[0;36mprocessS\u001b[0;34m(chunk)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessS\u001b[39m(chunk):\n\u001b[1;32m     32\u001b[0m     statementID \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m     statementProp \u001b[38;5;241m=\u001b[39m findProperty(chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#print(statementProp)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#print(chunk))\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     statementValue \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the statement nodes that contain references and qualifiers\n",
    "nodes = {}\n",
    "\n",
    "# Stores any errors to then print out at the end\n",
    "errors = []\n",
    "\n",
    "# Processes statements that start with WDQ:\n",
    "def processWD_Q(chunk):\n",
    "    subject = findQID(chunk.split(\" \")[0].split(\":\")[1])\n",
    "    predicate = chunk.split(\" \")[1]\n",
    "    if predicate.startswith(\"p:\") | predicate.startswith(\"wdt:p\"):\n",
    "        predicate = findProperty(predicate.split(\":\")[1])\n",
    "    object = chunk.split(\" \")[2]\n",
    "    if object.startswith(\"s:\"):\n",
    "        statementNodes.append(chunk.split(\"s:\")[1])\n",
    "    new_row = {\"subject\": subject, \"predicate\": predicate, \"object\": object}\n",
    "    statementList.append(new_row)\n",
    "    #print(new_row)\n",
    "\n",
    "# Processes statements that start with WDQ:\n",
    "def processWDT_P(chunk):\n",
    "    subject = chunk.split(\" \")[0]\n",
    "    subject = findProperty(subject.split(\":\")[1])\n",
    "    predicate = chunk.split(\" \")[1]\n",
    "    if predicate.startswith(\"p:\") or predicate.startswith(\"wdt:\"):\n",
    "        predicate = findProperty(predicate.split(\":\")[1])\n",
    "    new_row = {\"subject\": subject, \"predicate\": predicate, \"object\": object}\n",
    "    statementList.append(new_row)\n",
    "    #print(new_row)\n",
    "\n",
    "def processS(chunk):\n",
    "    statementID = chunk.split(\";\")[0].split(\" \")[0]\n",
    "    statementProp = findProperty(chunk.split(\";\")[2].split(\" \")[2].split(\":\")[1])\n",
    "    #print(statementProp)\n",
    "    #print(chunk))\n",
    "    statementValue = chunk.split(\";\")[2].split(\" \")[3]\n",
    "    if statementValue.startswith(\"wd:\"):\n",
    "        statementValue = findQID(statementValue.split(\":\")[1])\n",
    "    #print(f\"{statementProp} {statementValue}\")\n",
    "    for statement in statementList:\n",
    "        if statement[\"object\"] == statementID:\n",
    "            statement[\"object\"] = statementValue\n",
    "\n",
    "# Processes statements that start with S:\n",
    "# def processStatementNode(nodeID):\n",
    "#    statementProp = findProperty(chunk.split(\";\")[2].split(\" \")[2].split(\":\")[1])\n",
    "#    #print(statementProp)\n",
    "#    #print(chunk))\n",
    "#    statementValue = chunk.split(\";\")[2].split(\" \")[3]\n",
    "#    if statementValue.startswith(\"wd:\"):\n",
    "#        statementValue = findQID(statementValue.split(\":\")[1])\n",
    "#    #print(f\"{statementProp} {statementValue}\")\n",
    "#    for statement in statementList:\n",
    "#        if statement[\"object\"] == statementID:\n",
    "#            statement[\"object\"] = statementValue\n",
    "\n",
    "\n",
    "# Processes references (not implemented yet)\n",
    "#def processRef(chunk):\n",
    "#   #print(chunk)\n",
    "\n",
    "\n",
    "# Processes chunks based on their statement type\n",
    "def processChunk(chunk):\n",
    "    chunk = chunk.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    if (\n",
    "        chunk.startswith(\" <https://\")\n",
    "        | chunk.startswith(\" data:\")\n",
    "        | chunk.startswith(\"@prefix\")\n",
    "        | chunk.startswith(\"xsd:\")\n",
    "        | chunk.startswith(\"ontolex:\")\n",
    "        | chunk.startswith(\"dct:\")\n",
    "        | chunk.startswith(\"rdfs:\")\n",
    "        | chunk.startswith(\"owl:\")\n",
    "        | chunk.startswith(\"skos:\")\n",
    "        | chunk.startswith(\"schema:\")\n",
    "        | chunk.startswith(\"cc:\")\n",
    "        | chunk.startswith(\"geo:\")\n",
    "        | chunk.startswith(\"prov:\")\n",
    "        | chunk.startswith(\"data\")\n",
    "        | chunk.startswith(\"<\")\n",
    "    ):\n",
    "        pass\n",
    "    else:\n",
    "        chunk = chunk.lstrip()\n",
    "        output.write(chunk + \"\\n\")\n",
    "        if chunk.startswith(\"wd:Q\"):\n",
    "            processWD_Q(chunk)\n",
    "        if chunk.startswith(\"wdt:P\"):\n",
    "            processWDT_P(chunk)\n",
    "        if chunk.startswith(\"s:\"):\n",
    "            statementNodes.append(chunk)\n",
    "            processS(chunk)\n",
    "        if chunk.startswith(\"ref:\"):\n",
    "            referenceNodes.append(chunk)\n",
    "        if chunk.startswith(\"v:\"):\n",
    "            valueNodes.append(chunk)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "ttl_files_dir = \"./TTLFiles/\"\n",
    "\n",
    "# Processes each file in the directory, line by line, and writes the results to a TSV file\n",
    "for filename in tqdm.tqdm((os.listdir(ttl_files_dir))):\n",
    "#for filename in os.listdir(ttl_files_dir):\n",
    "    statementList = []\n",
    "    chunkList = []\n",
    "    statementNodes = []\n",
    "    referenceNodes = []\n",
    "    valueNodes = []\n",
    "\n",
    "    if filename.endswith(\".ttl\"):\n",
    "        file_path = os.path.join(ttl_files_dir, filename)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            chunk = \"\"\n",
    "            name = filename.split(\".\")[0].replace(\" \", \"_\")\n",
    "            output = open(f\"./ChunkOutput/v5-{name}-chunkOutput.txt\", \"a\")\n",
    "\n",
    "            # Iterate over each line in the file\n",
    "            for line in file:\n",
    "                # Append the line to the current chunk\n",
    "                chunk += line\n",
    "\n",
    "                # Check if the line ends with a '.'\n",
    "                if line.strip().endswith(\".\"):\n",
    "                    # Process the chunk\n",
    "                    processChunk(chunk)\n",
    "                    # Reset the chunk\n",
    "                    chunk = \"\"\n",
    "\n",
    "        with open(f\"./TSVFilesV6/{name}.tsv\", \"w\") as tsvFile:\n",
    "            name = statementList[0][\"subject\"]\n",
    "            for statement in statementList:\n",
    "                #print(statement)\n",
    "                if statement[\"subject\"] == name:\n",
    "                    tsvFile.write(\n",
    "                        f\"{statement['subject']}\\t{statement['predicate']}\\t{statement['object']}\\n\"\n",
    "                    )\n",
    "    output.close()\n",
    "    tsvFile.close()\n",
    "    file.close()\n",
    "    #for node in statementNodes:\n",
    "    #   #print(node)\n",
    "\n",
    "with open(\"properties.txt\", \"w\") as propOutput:\n",
    "    for prop in sorted(foundProps):\n",
    "        propOutput.write(f\"{prop}\\t{foundProps[prop]}\\t{PropsCount[prop]}\\n\")\n",
    "    propOutput.close()\n",
    "    \n",
    "with open(\"QIDs.txt\", \"w\") as qidOutput:\n",
    "    for qid in sorted(foundQIDs):\n",
    "        qidOutput.write(f\"{qid}\\t{foundQIDs[qid]}\\t{QIDCount[qid]}\\n\")\n",
    "    qidOutput.close()\n",
    "    \n",
    "with open(\"errors.txt\", \"w\") as file:\n",
    "    file.write(f\"{filename} Errors:\" + \"*\"*50 + \"\\n\\n\")\n",
    "    for error in errors:\n",
    "        file.write(error + \"\\n\")\n",
    "    file.write(\"\\n\\n\")\n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
